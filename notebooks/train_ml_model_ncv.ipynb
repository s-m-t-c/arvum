{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11294ccd-de96-4097-9b36-18a867aef810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV, SelectKBest, f_classif\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, make_scorer, roc_curve, roc_auc_score, auc\n",
    "import joblib\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import compress\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "working_dir = '/home/jovyan/arvum/data/dea_landcover/c3/training/'\n",
    "filename = '2015_training_data.csv'\n",
    "\n",
    "filename = os.path.join(working_dir, filename)\n",
    "# model_input = numpy.loadtxt(filename, skiprows=1)\n",
    "\n",
    "model_input = pd.read_csv(filename)\n",
    "random_state = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc996b-d789-42f9-894c-c46210df849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input[\"binary_class\"] = model_input[\"binary_class\"].apply(lambda x:1 if x==111 else 0)\n",
    "model_input[\"binary_class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb7c72-31f9-4e7e-9ad7-54290b9ae820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_variables = ['blue','red','green','nir','swir1','swir2','edev','sdev','bcdev', 'NDVI', 'MNDWI', 'BAI', 'BUI', 'BSI', 'TCG', 'TCW', 'TCB', 'NDMI', 'LAI', 'EVI', 'AWEI_sh', 'BAEI', 'NDSI', 'SAVI']\n",
    "\n",
    "# original pickle variables\n",
    "model_variables = ['nir', 'edev', 'sdev', 'NDVI', 'BUI', 'BSI', 'TCG', 'NDMI', 'LAI', 'EVI', 'SAVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522716d-9584-48c4-bc55-de099b9bb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_input['binary_class'].to_numpy()\n",
    "X = model_input[model_variables].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06696f-62b5-4d44-ad16-70375bc5e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "\n",
    "# Feature selection using LASSO\n",
    "#feature_selection = SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=10000))\n",
    "# set to all\n",
    "feature_selection = SelectKBest(f_classif, k='all')\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "        max_depth=50, max_leaf_nodes=None,\n",
    "                   #    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=3,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                       n_jobs=-1, oob_score=True, random_state=random_state, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "# Hyperparameter grid to explore\n",
    "param_grid = { \n",
    "            'max_depth': [20,30, 50],\n",
    "                'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "                }\n",
    "\n",
    "# To be used within GridSearch\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# To be used in outer CV (you asked for 10)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# iterate over parameter grid\n",
    "cv_model = GridSearchCV(estimator=model, param_grid=param_grid, cv= inner_cv, refit=True)\n",
    "\n",
    "# Pipe selected features into hyper parameter search\n",
    "pipe = Pipeline([('feature_selection', feature_selection),\n",
    "        ('classification', cv_model)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919d575-5c02-48bd-af3b-a03cf487f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'precision': 'precision',\n",
    "    'recall':'recall',\n",
    "    'f1_score': 'f1',\n",
    "    'Accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(pipe, X, y, cv=outer_cv, n_jobs=-1, scoring=scoring)\n",
    "for key, rsl in cv_results.items():\n",
    "    print(key, rsl.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit pipe\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82157d-2aea-4266-a37c-2288eac6e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features:\", pipe['classification'].best_estimator_.n_features_in_, \"/\", len(model_variables))\n",
    "model_variables = list(compress(model_variables, pipe['feature_selection'].get_support()))\n",
    "\n",
    "# Variable importance\n",
    "for var_name, var_importance in zip(model_variables, pipe['classification'].best_estimator_.feature_importances_):\n",
    "    print(\"{}: {:.04}\".format(var_name, var_importance))\n",
    "\n",
    "\n",
    "ml_model_dict = {}\n",
    "\n",
    "ml_model_dict['variables'] = model_variables\n",
    "ml_model_dict['classes'] = {'Cultivated' : 111,\n",
    "                            'Not Cultivated' : 0}\n",
    "ml_model_dict['classifier'] = pipe['classification'].best_estimator_\n",
    "ml_model_dict['accuracy']=cv_results['test_Accuracy']\n",
    "ml_model_dict['f1']=cv_results['test_f1_score']\n",
    "\n",
    "print(ml_model_dict)\n",
    "\n",
    "# Pickle model\n",
    "with open(os.path.join(working_dir, '2010_2015_median_model_indices_feature_selection_kbest_15.joblib'), 'wb') as f:\n",
    "    #pickle.dump(ml_model_dict, f)\n",
    "    joblib.dump(ml_model_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080dde1-b06f-4a30-a5ad-9cab79c872b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the trained model using the independant validation set \n",
    "\n",
    "working_dir = '/home/jovyan/arvum/data/dea_landcover/c3/validation/'\n",
    "\n",
    "# Change the year in filename to 2015 to inspect the 2015 results\n",
    "validation_filename = '2010_validation_data.csv'\n",
    "validation_filepath = os.path.join(working_dir, validation_filename)\n",
    "\n",
    "validation_data = pd.read_csv(validation_filepath)\n",
    "\n",
    "validation_data['output'] = validation_data['output'].apply(lambda x: 1 if x==111 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "\n",
    "y_test = validation_data['output'].to_numpy()\n",
    "validation_data.drop(labels=['output'], axis=1, inplace=True)\n",
    "X_test = validation_data[model_variables].to_numpy()\n",
    "\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Metrics \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print('Validation accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "print('Validation F1 Score: {0:0.4f}'. format(f1_score(y_test, y_pred)))\n",
    "print('Validation precision score: {0:0.4f}'. format(precision_score(y_test, y_pred)))\n",
    "print('Validation Recall score: {0:0.4f}'. format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a confusion matrix - note the cultivated class is 1\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm_data = {'y_test': y_test, 'y_pred': y_pred}\n",
    "\n",
    "cm_df = pd.DataFrame(cm_data)\n",
    "confusion_matrix = pd.crosstab(cm_df['y_test'], cm_df['y_pred'], rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "plt.title(f\"Validation Data {validation_filename[0:4]}\")\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
